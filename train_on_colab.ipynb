{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of drone_sseg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXd-U0SD5xIJ"
      },
      "source": [
        "# Clone the repo\n",
        "!git clone https://github.com/CSAILVision/semantic-segmentation-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yKYnfLa6WAs"
      },
      "source": [
        "# Mount google drive. Since the data is lost everytime colab is reset, we will store\n",
        "# the training data and checkpoints in Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61HHw8YW6nGo"
      },
      "source": [
        "# Installing kaggle api to download data from kaggle\n",
        "!pip install -q kaggle\n",
        "\n",
        "# You will need kaggle authentication json file to download data\n",
        "# See https://github.com/Kaggle/kaggle-api\n",
        "# \"To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com. \n",
        "# Then go to the 'Account' tab of your user profile (https://www.kaggle.com/<username>/account) and \n",
        "# select 'Create API Token'. This will trigger the download of kaggle.json, a file containing your API credentials.\"\n",
        "\n",
        "# upload kaggle json file\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2CfaKS38sOs"
      },
      "source": [
        "# downloading data from kaggle\n",
        "!kaggle datasets download -d bulentsiyah/semantic-drone-dataset -p /content/gdrive/My\\ Drive/drone_sseg_training_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfhfqwlcA0cE"
      },
      "source": [
        "# unzipping the downloaded data\n",
        "!mkdir /content/gdrive/MyDrive/drone_sseg_training_data/drone_data\n",
        "!unzip -q /content/gdrive/MyDrive/drone_sseg_training_data/semantic-drone-dataset.zip -d /content/gdrive/MyDrive/drone_sseg_training_data/drone_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqXLIRYrD_Rh"
      },
      "source": [
        "# The RGB images in the training data are JEPGs, but the pipeline expects them in PNG format\n",
        "# convert all JPGs to PNGs and resize to fit into GPU. 6000*4000 are really big for a GPU\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "img_dir = \"/content/gdrive/MyDrive/drone_sseg_training_data/drone_data/dataset/semantic_drone_dataset/original_images\"\n",
        "for img in tqdm(os.listdir(img_dir)):\n",
        "  img_path = os.path.join(img_dir, img)\n",
        "  im = Image.open(img_path)\n",
        "  im = im.resize((1200,800), Image.ANTIALIAS)\n",
        "  im.save(img_path.replace(\".jpg\", \".png\"))\n",
        "  os.remove(img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaAHfumrMrXc"
      },
      "source": [
        "# resizing labels\n",
        "img_dir = \"/content/gdrive/MyDrive/drone_sseg_training_data/drone_data/dataset/semantic_drone_dataset/label_images_semantic\"\n",
        "for img in tqdm(os.listdir(img_dir)):\n",
        "  img_path = os.path.join(img_dir, img)\n",
        "  im = Image.open(img_path)\n",
        "  im = im.resize((1200,800), Image.ANTIALIAS)  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QT44SX6M9wr"
      },
      "source": [
        "# create .odgt files for training, and split data into training and validation sets\n",
        "# TODO: add script "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72ScXOfMF32o"
      },
      "source": [
        "# installing additional dependencies\n",
        "!pip install yacs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th6vf0qjjZdO"
      },
      "source": [
        "# Optional: Connecting colab with ssh. I like to monitor GPU usage using \"watch -n1 nvidia-smi\"\n",
        "!pip install colab_ssh --upgrade\n",
        "from colab_ssh import launch_ssh\n",
        "launch_ssh(\"your ngrok id\", \"some password\")\n",
        "# Run following command in your terminal (replace the port and tcp number)\n",
        "# ssh -p 15892 root@0.tcp.ngrok.io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkYSjNnxRzye"
      },
      "source": [
        "# Time to start training\n",
        "# A few changes: (a). The pipeline was originally designed to run on multiple GPUs.\n",
        "# Since we will be running on a single GPU, change the train.py according to this issue - https://github.com/CSAILVision/semantic-segmentation-pytorch/issues/58\n",
        "# Update the paths and other parameters in the config file. You can also use the one I have uploaded in the config folder\n",
        "import os\n",
        "os.chdir('/content/semantic-segmentation-pytorch')\n",
        "!python train.py --cfg ade20k-hrnetv2.yaml --gpus 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NENtz4D84oBU"
      },
      "source": [
        "# Run model on valdation images\n",
        "# Note that the test.py expects JPEGs only. \n",
        "# You can update the find_recursive function in mit_semseg/utils.py to run on images of your desired format.\n",
        "!python test.py --cfg config/drone_sseg.yaml --gpu 0 --imgs /content/gdrive/MyDrive/drone_sseg_training_data/drone_data/dataset/semantic_drone_dataset/validation/images"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
